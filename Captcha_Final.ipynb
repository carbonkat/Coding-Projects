{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carbonkat/Coding-Projects/blob/main/Captcha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0SF_zk0i9xII"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import matplotlib.pylab as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import normal\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.data as data\n",
        "import skimage.segmentation as seg\n",
        "import skimage.filters as filters\n",
        "import skimage.draw as draw\n",
        "import skimage.color as color\n",
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsslsK-7-AUg",
        "outputId": "ae50b24a-d0fd-4b3a-eb2f-17b6d30284c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J_SXgXYA-TDf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def image_processing(image):\n",
        "  #first convert image to grayscale\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  (thresh, blackAndWhiteImage) = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "  #close holes in characters to make continuous lines\n",
        "  kernel = np.ones((2,3),np.uint8)\n",
        "  close = cv2.morphologyEx(blackAndWhiteImage, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  #open up spaces between defined lines\n",
        "  opening = cv2.morphologyEx(close, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "  #thin lines to remove occluding line\n",
        "  kernel = np.ones((2,2),np.uint8)\n",
        "  erosion = cv2.erode(opening,kernel,iterations = 1)\n",
        "\n",
        "  opening2 = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, np.ones((2,1),np.uint8))\n",
        "\n",
        "  return opening2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oO1qBS6T-VaS"
      },
      "outputs": [],
      "source": [
        "def get_letters(image):\n",
        "  x, y, w, h = 30, 12, 21, 38\n",
        "  letters = []\n",
        "  for  i in range(5):\n",
        "    # get the bounding rectangle\n",
        "    #image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
        "    letter = image[y:y+h,x:x+w]\n",
        "    letter = cv2.resize(letter, (28, 28))\n",
        "    letters.append(letter)\n",
        "    x += w\n",
        "  return letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Y82Kykqa-YyS"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "download_path = '/content/gdrive/My Drive/Colab_Notebooks/input/samples'\n",
        "#obtain all images using recursive downloading through glob module\n",
        "images = glob.glob(download_path + '/*.png')\n",
        "\n",
        "def get_name(image):\n",
        "  path = image.split('samples/')\n",
        "  path = path[1].split('.')\n",
        "  name = path[0]\n",
        "  if len(name) > 5:\n",
        "    print(name)\n",
        "  return name\n",
        "\n",
        "def build_character_list(image_paths):\n",
        "  indiv_characters = []\n",
        "  indiv_labels = []\n",
        "  for image_path in image_paths:\n",
        "    #read in captcha image\n",
        "    image = io.imread(image_path)\n",
        "    image_processed = image_processing(image)\n",
        "    letters = get_letters(image_processed)\n",
        "    #get name\n",
        "    name = get_name(image_path)\n",
        "    for i in range(5):\n",
        "      indiv_characters.append(letters[i])\n",
        "      indiv_labels.append(str_to_one_hot(name[i]))\n",
        "    #print(\"done!\")\n",
        "  return indiv_characters, indiv_labels\n",
        "\n",
        "#one hot encoding of labels\n",
        "def str_to_one_hot(str):\n",
        "  vals = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o',\n",
        "          'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "  #get the index of the string---this will be its encoded value\n",
        "  ind = vals.index(str)\n",
        "  return ind"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from random import shuffle\n",
        "\n",
        "def explore(labels):\n",
        "  tally = Counter(labels)\n",
        "  return tally\n",
        "\n",
        "def oversample(images, labels, tally):\n",
        "  random.seed(42)\n",
        "  max = tally.most_common()[0][1]\n",
        "  print(max)\n",
        "  for i in tally.items():\n",
        "    count = i[1]\n",
        "    indices = [j for j, x in enumerate(labels) if x == i[0]]\n",
        "    while count < max:\n",
        "      #reshuffle each time to ensure randomness\n",
        "      shuffle(indices)\n",
        "      labels.append(labels[indices[0]])\n",
        "      images.append(np.copy(images[indices[0]]))\n",
        "      count += 1\n",
        "  print(Counter(labels))"
      ],
      "metadata": {
        "id": "eg6G84ZtDjzC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_FfMDBUTD-ph"
      },
      "outputs": [],
      "source": [
        "#takes in a list of images and converts to characters and labels\n",
        "class CaptchaDataset(Dataset):\n",
        "    \"\"\"Captcha dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, image_list, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_list (list): list of paths to images\n",
        "            transforms (list): list of transforms to be applied to the data\n",
        "        \"\"\"\n",
        "        self.characters, self.labels = build_character_list(image_list)\n",
        "        oversample(self.characters, self.labels, explore(self.labels))\n",
        "        self.transform = transform\n",
        "        self.count = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.characters)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #if the index is a tensor, convert to a list\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        x, y = self.characters[idx], self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            x, y = self.transform(x,y)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FGyckxXraFOc"
      },
      "outputs": [],
      "source": [
        "#helper class to convert everything to tensors\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        letter, solution = x, y\n",
        "        letter = np.expand_dims(letter, axis=0)\n",
        "        transp_letter = torch.Tensor(letter)\n",
        "        # the solution also needs to be converted to a tensor\n",
        "        solution = torch.tensor(solution,dtype=torch.float32) \n",
        "        return transp_letter, solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfpYPqGlaIos",
        "outputId": "013be5e6-bdc5-4d86-ce0e-1d3f4553f1e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "452\n",
            "Counter({2: 452, 11: 452, 24: 452, 31: 452, 10: 452, 7: 452, 33: 452, 5: 452, 14: 452, 6: 452, 12: 452, 15: 452, 13: 452, 3: 452, 22: 452, 4: 452, 21: 452, 1: 452, 32: 452})\n",
            "73\n",
            "Counter({7: 73, 11: 73, 21: 73, 3: 73, 5: 73, 14: 73, 22: 73, 10: 73, 15: 73, 32: 73, 2: 73, 1: 73, 24: 73, 12: 73, 31: 73, 4: 73, 13: 73, 33: 73, 6: 73})\n",
            "length of training dataset:  8588\n",
            "length of testing dataset:  1387\n",
            "0 tensor(2.)\n",
            "torch.Size([1, 28, 28])\n",
            "<class 'torch.Tensor'>\n",
            "1 tensor(11.)\n",
            "torch.Size([1, 28, 28])\n",
            "<class 'torch.Tensor'>\n",
            "2 tensor(24.)\n",
            "torch.Size([1, 28, 28])\n",
            "<class 'torch.Tensor'>\n",
            "3 tensor(31.)\n",
            "torch.Size([1, 28, 28])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "#randomly shuffle images to ensure datasets are unbiased\n",
        "random.seed(42)\n",
        "random.shuffle(images)\n",
        "train_dataset = CaptchaDataset(images[:900], transform=ToTensor())\n",
        "test_dataset = CaptchaDataset(images[900:], transform=ToTensor())\n",
        "print(\"length of training dataset: \", len(train_dataset))\n",
        "print(\"length of testing dataset: \", len(test_dataset))\n",
        "\n",
        "#check that the datatypes and shapes of the first four datapoints are correct\n",
        "for i in range(4):\n",
        "    x, y = train_dataset[i]\n",
        "    print(i, y)\n",
        "    print(x.size())\n",
        "    print(type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "r4tcVRK_aM8u"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=256,\n",
        "                        shuffle=True, num_workers=2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nQ3cuUA7aQla"
      },
      "outputs": [],
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        #print(x.view(x.shape[0],-1))\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "class Reshape(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(-1,1,28,28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ceU1L69eaT76"
      },
      "outputs": [],
      "source": [
        "le_net = torch.nn.Sequential(\n",
        "    Reshape(),\n",
        "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
        "    nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    Flatten(),\n",
        "    nn.Linear(in_features=16*5*5, out_features=120),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(120, 84),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(84, 35)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IyQJIGa5aXbH"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy_updated(data_iter, net,device=torch.device('cpu')):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
        "    for X,y in data_iter:\n",
        "        # If device is the GPU, copy the data to the GPU.\n",
        "        X,y = X.to(device),y.to(device)\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
        "            n += y.shape[0]\n",
        "    return acc_sum.item()/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QYJdn-ISabGf"
      },
      "outputs": [],
      "source": [
        "def try_gpu():\n",
        "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "device = try_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6nqCxT1YafUj"
      },
      "outputs": [],
      "source": [
        "def train_model_lenet(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None):\n",
        "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
        "        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
        "        n, start = 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            net.train()\n",
        "            #print(X.type)\n",
        "            #print(y.type)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            X,y = X.to(device),y.to(device) \n",
        "            #print(X)\n",
        "            #print(y)\n",
        "            y_hat = net(X)\n",
        "            y = y.type(torch.LongTensor)\n",
        "            #print(y_hat.dtype)\n",
        "            #print(y.dtype)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                y = y.long()\n",
        "                train_l_sum += loss.float()\n",
        "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
        "                n += y.shape[0]\n",
        "        test_acc = evaluate_accuracy_updated(test_iter, net,device)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
        "              'time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n",
        "                 time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zRJP9RUajPV",
        "outputId": "d10a7c04-3f1f-46e2-d39e-c8463422cb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cpu\n",
            "epoch 1, loss 0.0121, train acc 0.060, test acc 0.053, time 5.2 sec\n",
            "epoch 2, loss 0.0118, train acc 0.061, test acc 0.053, time 4.3 sec\n",
            "epoch 3, loss 0.0117, train acc 0.068, test acc 0.125, time 4.2 sec\n",
            "epoch 4, loss 0.0110, train acc 0.121, test acc 0.222, time 3.5 sec\n",
            "epoch 5, loss 0.0090, train acc 0.290, test acc 0.363, time 3.1 sec\n",
            "epoch 6, loss 0.0073, train acc 0.445, test acc 0.420, time 3.1 sec\n",
            "epoch 7, loss 0.0063, train acc 0.510, test acc 0.539, time 3.0 sec\n",
            "epoch 8, loss 0.0054, train acc 0.605, test acc 0.637, time 3.0 sec\n",
            "epoch 9, loss 0.0048, train acc 0.647, test acc 0.635, time 2.9 sec\n",
            "epoch 10, loss 0.0044, train acc 0.681, test acc 0.663, time 3.0 sec\n",
            "epoch 11, loss 0.0040, train acc 0.707, test acc 0.690, time 3.0 sec\n",
            "epoch 12, loss 0.0037, train acc 0.731, test acc 0.712, time 4.1 sec\n",
            "epoch 13, loss 0.0033, train acc 0.766, test acc 0.730, time 3.2 sec\n",
            "epoch 14, loss 0.0032, train acc 0.773, test acc 0.766, time 2.9 sec\n",
            "epoch 15, loss 0.0029, train acc 0.788, test acc 0.781, time 2.8 sec\n",
            "epoch 16, loss 0.0031, train acc 0.774, test acc 0.794, time 2.8 sec\n",
            "epoch 17, loss 0.0026, train acc 0.814, test acc 0.792, time 2.9 sec\n",
            "epoch 18, loss 0.0025, train acc 0.820, test acc 0.790, time 2.9 sec\n",
            "epoch 19, loss 0.0025, train acc 0.817, test acc 0.789, time 2.8 sec\n",
            "epoch 20, loss 0.0023, train acc 0.830, test acc 0.831, time 2.9 sec\n",
            "epoch 21, loss 0.0022, train acc 0.832, test acc 0.836, time 2.8 sec\n",
            "epoch 22, loss 0.0022, train acc 0.841, test acc 0.840, time 2.9 sec\n",
            "epoch 23, loss 0.0021, train acc 0.845, test acc 0.839, time 2.9 sec\n",
            "epoch 24, loss 0.0020, train acc 0.852, test acc 0.802, time 2.8 sec\n",
            "epoch 25, loss 0.0020, train acc 0.850, test acc 0.810, time 2.9 sec\n",
            "epoch 26, loss 0.0019, train acc 0.854, test acc 0.802, time 2.8 sec\n",
            "epoch 27, loss 0.0018, train acc 0.863, test acc 0.856, time 2.8 sec\n",
            "epoch 28, loss 0.0017, train acc 0.871, test acc 0.839, time 2.9 sec\n",
            "epoch 29, loss 0.0017, train acc 0.872, test acc 0.842, time 2.9 sec\n",
            "epoch 30, loss 0.0016, train acc 0.876, test acc 0.852, time 2.9 sec\n"
          ]
        }
      ],
      "source": [
        "lr, num_epochs = 0.9, 30\n",
        "batch_size = 256\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "le_net.apply(init_weights)\n",
        "le_net = le_net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_model_lenet(le_net, train_dataloader, test_dataloader, criterion,num_epochs, batch_size,device, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uI-EEAmanDa",
        "outputId": "6c185fbc-aa07-4e52-b73d-c72c20ab4c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1, 28, 28])\n",
            "\n",
            "True: 8 Predicted: 8\n",
            "True: c Predicted: c\n",
            "True: m Predicted: m\n",
            "True: 4 Predicted: 4\n",
            "True: 6 Predicted: 6\n",
            "True: f Predicted: f\n",
            "True: n Predicted: n\n",
            "True: c Predicted: c\n",
            "True: n Predicted: f\n",
            "True: b Predicted: n\n",
            "True: g Predicted: g\n",
            "True: 8 Predicted: 8\n",
            "True: 8 Predicted: 8\n",
            "True: 8 Predicted: 8\n",
            "True: x Predicted: 6\n",
            "True: n Predicted: n\n",
            "True: x Predicted: x\n",
            "True: c Predicted: c\n",
            "True: m Predicted: n\n",
            "True: n Predicted: m\n",
            "True: 8 Predicted: 8\n",
            "True: 3 Predicted: 3\n",
            "True: 2 Predicted: 2\n",
            "True: f Predicted: f\n",
            "True: 3 Predicted: 3\n",
            "True: 6 Predicted: 6\n",
            "True: 4 Predicted: 4\n",
            "True: b Predicted: b\n",
            "True: 3 Predicted: 3\n",
            "True: p Predicted: p\n",
            "True: 8 Predicted: 8\n",
            "True: d Predicted: d\n",
            "True: 4 Predicted: 4\n",
            "True: w Predicted: w\n",
            "True: m Predicted: m\n",
            "True: 6 Predicted: 6\n",
            "True: 5 Predicted: 5\n",
            "True: m Predicted: n\n",
            "True: 8 Predicted: 8\n",
            "True: 5 Predicted: 5\n",
            "True: e Predicted: e\n",
            "True: 2 Predicted: 2\n",
            "True: m Predicted: n\n",
            "True: g Predicted: m\n",
            "True: 2 Predicted: x\n",
            "True: m Predicted: m\n",
            "True: m Predicted: n\n",
            "True: g Predicted: m\n",
            "True: 2 Predicted: 2\n",
            "True: m Predicted: p\n",
            "True: x Predicted: x\n",
            "True: f Predicted: f\n",
            "True: g Predicted: g\n",
            "True: x Predicted: n\n",
            "True: b Predicted: b\n",
            "True: c Predicted: c\n",
            "True: w Predicted: w\n",
            "True: g Predicted: x\n",
            "True: y Predicted: n\n",
            "True: x Predicted: c\n",
            "True: e Predicted: e\n",
            "True: w Predicted: w\n",
            "True: c Predicted: n\n",
            "True: f Predicted: f\n",
            "True: 5 Predicted: 5\n",
            "True: m Predicted: m\n",
            "True: x Predicted: x\n",
            "True: n Predicted: n\n",
            "True: w Predicted: n\n",
            "True: 4 Predicted: w\n",
            "True: 7 Predicted: 7\n",
            "True: 8 Predicted: 8\n",
            "True: e Predicted: e\n",
            "True: e Predicted: e\n",
            "True: c Predicted: c\n",
            "True: b Predicted: b\n",
            "True: b Predicted: b\n",
            "True: y Predicted: y\n",
            "True: m Predicted: n\n",
            "True: y Predicted: w\n",
            "True: n Predicted: n\n",
            "True: f Predicted: f\n",
            "True: d Predicted: d\n",
            "True: 8 Predicted: 8\n",
            "True: g Predicted: g\n",
            "True: x Predicted: x\n",
            "True: d Predicted: d\n",
            "True: c Predicted: c\n",
            "True: n Predicted: n\n",
            "True: 4 Predicted: 4\n",
            "True: g Predicted: g\n",
            "True: d Predicted: d\n",
            "True: 4 Predicted: 4\n",
            "True: m Predicted: m\n",
            "True: f Predicted: f\n",
            "True: 7 Predicted: 7\n",
            "True: 8 Predicted: 8\n",
            "True: 5 Predicted: 5\n",
            "True: n Predicted: n\n",
            "True: 4 Predicted: 4\n",
            "True: 4 Predicted: 4\n",
            "True: f Predicted: f\n",
            "True: c Predicted: c\n",
            "True: 3 Predicted: 3\n",
            "True: 6 Predicted: 6\n",
            "True: 8 Predicted: 8\n",
            "True: e Predicted: e\n",
            "True: 3 Predicted: 3\n",
            "True: 2 Predicted: 2\n",
            "True: m Predicted: n\n",
            "True: d Predicted: d\n",
            "True: 2 Predicted: 2\n",
            "True: 2 Predicted: 2\n",
            "True: n Predicted: n\n",
            "True: 7 Predicted: 7\n",
            "True: b Predicted: b\n",
            "True: c Predicted: c\n",
            "True: 8 Predicted: 8\n",
            "True: n Predicted: n\n",
            "True: f Predicted: f\n",
            "True: p Predicted: p\n",
            "True: y Predicted: y\n",
            "True: e Predicted: e\n",
            "True: f Predicted: f\n",
            "True: b Predicted: b\n",
            "True: 3 Predicted: 5\n",
            "True: x Predicted: x\n",
            "True: n Predicted: n\n",
            "True: g Predicted: g\n",
            "True: 6 Predicted: 6\n",
            "True: w Predicted: w\n",
            "True: 8 Predicted: 8\n",
            "True: b Predicted: b\n",
            "True: n Predicted: m\n",
            "True: x Predicted: n\n",
            "True: 7 Predicted: 7\n",
            "True: g Predicted: g\n",
            "True: m Predicted: n\n",
            "True: f Predicted: 6\n",
            "True: 3 Predicted: 5\n",
            "True: 4 Predicted: 4\n",
            "True: c Predicted: c\n",
            "True: 8 Predicted: 8\n",
            "True: n Predicted: n\n",
            "True: 8 Predicted: 8\n",
            "True: p Predicted: p\n",
            "True: f Predicted: f\n",
            "True: 4 Predicted: 4\n",
            "True: n Predicted: n\n",
            "True: b Predicted: b\n",
            "True: p Predicted: p\n",
            "True: b Predicted: b\n",
            "True: p Predicted: p\n",
            "True: g Predicted: p\n",
            "True: c Predicted: p\n",
            "True: w Predicted: w\n",
            "True: x Predicted: c\n",
            "True: y Predicted: e\n",
            "True: 4 Predicted: f\n",
            "True: n Predicted: 4\n",
            "True: b Predicted: b\n",
            "True: g Predicted: g\n",
            "True: b Predicted: b\n",
            "True: 4 Predicted: 4\n",
            "True: 8 Predicted: 8\n",
            "True: n Predicted: n\n",
            "True: 7 Predicted: 7\n",
            "True: f Predicted: f\n",
            "True: f Predicted: f\n",
            "True: 2 Predicted: 2\n",
            "True: 7 Predicted: 7\n",
            "True: d Predicted: d\n",
            "True: g Predicted: g\n",
            "True: c Predicted: c\n",
            "True: 2 Predicted: 2\n",
            "True: g Predicted: g\n",
            "True: 7 Predicted: 7\n",
            "True: g Predicted: g\n",
            "True: n Predicted: n\n",
            "True: f Predicted: f\n",
            "True: n Predicted: n\n",
            "True: 8 Predicted: 6\n",
            "True: f Predicted: f\n",
            "True: p Predicted: p\n",
            "True: 6 Predicted: 6\n",
            "True: m Predicted: m\n",
            "True: m Predicted: m\n",
            "True: 3 Predicted: 3\n",
            "True: n Predicted: n\n",
            "True: n Predicted: n\n",
            "True: 8 Predicted: 8\n",
            "True: f Predicted: f\n",
            "True: e Predicted: e\n",
            "True: x Predicted: x\n",
            "True: n Predicted: n\n",
            "True: c Predicted: c\n",
            "True: e Predicted: e\n",
            "True: n Predicted: n\n",
            "True: 5 Predicted: 5\n",
            "True: 5 Predicted: 5\n",
            "True: e Predicted: e\n",
            "True: 4 Predicted: 4\n",
            "True: 6 Predicted: 6\n",
            "True: p Predicted: p\n",
            "True: d Predicted: d\n",
            "True: 6 Predicted: b\n",
            "True: d Predicted: d\n",
            "True: m Predicted: m\n",
            "True: x Predicted: n\n",
            "True: 7 Predicted: c\n",
            "True: 7 Predicted: 7\n",
            "True: y Predicted: y\n",
            "True: f Predicted: f\n",
            "True: 6 Predicted: 6\n",
            "True: 2 Predicted: 2\n",
            "True: n Predicted: n\n",
            "True: m Predicted: n\n",
            "True: y Predicted: n\n",
            "True: 2 Predicted: c\n",
            "True: x Predicted: c\n",
            "True: f Predicted: f\n",
            "True: g Predicted: g\n",
            "True: 7 Predicted: 7\n",
            "True: m Predicted: m\n",
            "True: g Predicted: g\n",
            "True: 6 Predicted: 6\n",
            "True: f Predicted: f\n",
            "True: 8 Predicted: 8\n",
            "True: 5 Predicted: 5\n",
            "True: 7 Predicted: 7\n",
            "True: y Predicted: y\n",
            "True: m Predicted: m\n",
            "True: p Predicted: b\n",
            "True: 7 Predicted: 7\n",
            "True: g Predicted: g\n",
            "True: m Predicted: n\n",
            "True: 3 Predicted: 5\n",
            "True: w Predicted: w\n",
            "True: f Predicted: f\n",
            "True: w Predicted: f\n",
            "True: 4 Predicted: 6\n",
            "True: n Predicted: n\n",
            "True: 3 Predicted: 3\n",
            "True: m Predicted: m\n",
            "True: n Predicted: n\n",
            "True: m Predicted: n\n",
            "True: p Predicted: g\n",
            "True: 7 Predicted: 7\n",
            "True: w Predicted: f\n",
            "True: p Predicted: m\n",
            "True: n Predicted: n\n",
            "True: 7 Predicted: 7\n",
            "True: e Predicted: e\n",
            "True: b Predicted: b\n",
            "True: x Predicted: x\n",
            "True: n Predicted: n\n"
          ]
        }
      ],
      "source": [
        "for X, y in test_dataloader:\n",
        "    break\n",
        "\n",
        "def get_labels(label):\n",
        "  vals = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o',\n",
        "          'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "  #get the index of the string---this will be its encoded value\n",
        "  return [vals[int(i)] for i in label]\n",
        "\n",
        "#numpy array of predictions\n",
        "print(X.shape)\n",
        "true_labels = get_labels(y.numpy())\n",
        "pred_labels = get_labels(le_net(X).argmax(dim=1).numpy())\n",
        "print()\n",
        "for i in range(len(true_labels)):\n",
        "  print(\"True:\", true_labels[i], \"Predicted:\", pred_labels[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOl+8bxaUCqRpUm8t0KGN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}